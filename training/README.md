# Training Data for Hush Engine

This directory contains training feedback collected from the Hush macOS app to improve PII detection accuracy.

## Directory Structure

```
training/
├── README.md           # This file
└── feedback/           # User feedback JSON files
    └── feedback_*.json # Individual feedback entries
```

## Feedback Format

Each feedback file is a JSON document with the following structure:

```json
{
  "timestamp": "2026-02-02T16:46:35.000Z",
  "fileName": "document.pdf",
  "filePath": "/Users/.../document.pdf",
  "detectedText": "John Smith",
  "detectedEntityType": "PERSON",
  "bbox": {
    "x": 100.0,
    "y": 200.0,
    "width": 150.0,
    "height": 20.0
  },
  "page": 1,
  "confidence": 0.85,
  "suggestedEntityTypes": ["PERSON", "COMPANY"],
  "notes": "User notes about the detection",
  "engineVersion": "1.1.1"
}
```

### Fields

| Field | Type | Description |
|-------|------|-------------|
| `timestamp` | ISO 8601 | When the feedback was submitted |
| `fileName` | string | Name of the processed file |
| `filePath` | string | Full path to the file (for reference only) |
| `detectedText` | string | The text that was detected |
| `detectedEntityType` | string | What the engine classified it as |
| `bbox` | object | Bounding box coordinates (nullable) |
| `page` | int | Page number for PDFs (nullable, 1-indexed) |
| `confidence` | float | Engine's confidence score (0.0-1.0) |
| `suggestedEntityTypes` | array | User's suggested correct entity types |
| `notes` | string | Free-form user notes |
| `engineVersion` | string | Version of hush-engine that made the detection |

## Entity Types

Valid entity types that may appear in `detectedEntityType` or `suggestedEntityTypes`:

**Personal Identity**: `PERSON`, `FACE`, `GENDER`, `NRP`
**Contact Information**: `EMAIL_ADDRESS`, `PHONE_NUMBER`, `URL`
**Government IDs**: `SSN`, `PASSPORT`, `DRIVER_LICENSE`, `ITIN`
**Financial**: `CREDIT_CARD`, `BANK_NUMBER`, `IBAN_CODE`, `FINANCIAL`, `CRYPTO`
**Location**: `LOCATION`, `COORDINATES`
**Medical**: `MEDICAL`, `MEDICAL_LICENSE`
**Technical/Device**: `IP_ADDRESS`, `DEVICE_ID`, `VEHICLE_ID`
**Document Elements**: `DATE_TIME`, `QR_CODE`, `BARCODE`
**Organization**: `COMPANY`
**Other**: `CUSTOM`, `UNKNOWN`

## Using Feedback for Training

### 1. Analyze Feedback Patterns

Look for common patterns where the engine made mistakes:

```python
import json
from pathlib import Path
from collections import Counter

feedback_dir = Path("training/feedback")
misclassifications = Counter()

for file in feedback_dir.glob("*.json"):
    with open(file) as f:
        entry = json.load(f)
        detected = entry["detectedEntityType"]
        suggested = entry["suggestedEntityTypes"]

        if detected not in suggested and suggested:
            misclassifications[(detected, tuple(suggested))] += 1

print("Common misclassifications:")
for (detected, suggested), count in misclassifications.most_common(10):
    print(f"  {detected} -> {suggested}: {count}")
```

### 2. Extract Training Examples

Generate training data for specific recognizers:

```python
# Extract false negatives (missed detections)
false_negatives = []
for file in feedback_dir.glob("*.json"):
    with open(file) as f:
        entry = json.load(f)
        if entry["detectedEntityType"] == "UNKNOWN" and entry["suggestedEntityTypes"]:
            false_negatives.append({
                "text": entry["detectedText"],
                "entity_type": entry["suggestedEntityTypes"][0],
                "notes": entry["notes"]
            })
```

### 3. Adjust Confidence Thresholds

Use feedback to tune per-entity confidence thresholds:

```python
# Analyze confidence scores for correct vs incorrect detections
correct_confidences = []
incorrect_confidences = []

for file in feedback_dir.glob("*.json"):
    with open(file) as f:
        entry = json.load(f)
        detected = entry["detectedEntityType"]
        suggested = entry["suggestedEntityTypes"]
        confidence = entry["confidence"]

        if detected in suggested:
            correct_confidences.append((detected, confidence))
        else:
            incorrect_confidences.append((detected, confidence))
```

## Best Practices

1. **Don't delete feedback files** - Archive them after processing
2. **Track by engine version** - Filter feedback by `engineVersion` to measure improvements
3. **Preserve privacy** - The `filePath` field is for reference; don't store actual file contents
4. **Batch processing** - Process feedback periodically rather than in real-time

## Source

Feedback is generated by the Hush macOS app (https://github.com/NewMediaStudio/hush) when users flag detections for correction. The app writes directly to this directory.
